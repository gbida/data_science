{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print [bs.h1.text] result\n",
      "\n",
      "\n",
      "      \n",
      "      \n",
      "      중고거래 인기매물\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "html = urlopen('https://www.daangn.com/hot_articles')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print('print [bs.h1.text] result\\n')\n",
    "print(bs.h1.text)\n",
    "# print(bs.findAll('meta'))  # bs, bs.h1, bs.head, bs.body, so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print [pythonscraping page1.html] result\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<title>A Useful Page</title>\n",
      "</head>\n",
      "<body>\n",
      "<h1>An Interesting Title</h1>\n",
      "<div>\n",
      "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print('print [pythonscraping page1.html] result\\n')\n",
    "print(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to handle errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\thtml = urlopen('http://www.pythonscraping.com/pages/error.html')\n",
    "except HTTPError:\n",
    "\tprint(HTTPError)\n",
    "except URLError:\n",
    "\tprint('The server could not be found')\n",
    "else:\n",
    "\tprint('It worked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# when tag is not exist\n",
    "def getTitle(url, tag):\n",
    "\ttry:\n",
    "\t\thtml = urlopen(url)\n",
    "\texcept HTTPError as e:\n",
    "\t\treturn None\n",
    "\ttry:\n",
    "\t\tbsObj = BeautifulSoup(html.read(), 'html.parser')\n",
    "\t\tvalue = bsObj.body.find(tag)\n",
    "\texcept AttributeError as e:\n",
    "\t\treturn None\n",
    "\treturn value\n",
    "\n",
    "# tag = 'h2'\n",
    "tag = 'h1'\n",
    "value = getTitle('http://www.pythonscraping.com/pages/page1.html', tag)\n",
    "\n",
    "if value is None:\n",
    "\tprint('{0} could not be found'.format(tag))\n",
    "else:\n",
    "\tprint(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to access to elements by html tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup.title\n",
      "<title>BeautifulSoup 활용</title>\n",
      "\n",
      "soup.title.text\n",
      "BeautifulSoup 활용\n",
      "\n",
      "soup.title.get_text()\n",
      "BeautifulSoup 활용\n",
      "\n",
      "soup.title.parent\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n",
      "\n",
      "soup.body\n",
      "<body>\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "<p>Paragraph</p>\n",
      "<span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n",
      "<h1 id=\"footer\">Footer</h1>\n",
      "</body>\n",
      "\n",
      "soup.h1\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "\n",
      "soup.h1.get_text()\n",
      "Heading 1\n",
      "\n",
      "soup.a\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "\n",
      "soup.a.text\n",
      "google\n",
      "\n",
      "soup.p\n",
      "<p>Paragraph</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html_example = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>BeautifulSoup 활용</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 id=\"heading\">Heading 1</h1>\n",
    "    <p>Paragraph</p>\n",
    "    <span class=\"red\">BeautifulSoup Library Examples!</span>\n",
    "    <div id=\"link\">\n",
    "        <a class=\"external_link\" href=\"www.google.com\">google</a>\n",
    "\n",
    "        <div id=\"class1\">\n",
    "            <p id=\"first\">class1's first paragraph</p>\n",
    "            <a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
    "\n",
    "            <p id=\"second\">class1's second paragraph</p>\n",
    "            <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
    "            <p id=\"third\">class1's third paragraph</p>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div id=\"text_id2\">\n",
    "        Example page\n",
    "        <p>g</p>\n",
    "    </div>\n",
    "    <h1 id=\"footer\">Footer</h1>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html_example, 'html.parser')\n",
    "print(f'soup.title\\n{soup.title}\\n')\n",
    "print(f'soup.title.text\\n{soup.title.text}\\n')\n",
    "print(f'soup.title.get_text()\\n{soup.title.get_text()}\\n')\n",
    "print(f'soup.title.parent\\n{soup.title.parent}\\n')\n",
    "print(f'soup.body\\n{soup.body}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup.h1\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "\n",
      "soup.h1.get_text()\n",
      "Heading 1\n",
      "\n",
      "soup.a\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "\n",
      "soup.a.text\n",
      "google\n",
      "\n",
      "soup.p\n",
      "<p>Paragraph</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'soup.h1\\n{soup.h1}\\n')\n",
    "print(f'soup.h1.get_text()\\n{soup.h1.get_text()}\\n')\n",
    "print(f'soup.a\\n{soup.a}\\n')\n",
    "print(f'soup.a.text\\n{soup.a.text}\\n')\n",
    "print(f'soup.p\\n{soup.p}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### find(), find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div> tag data\n",
      "<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>\n",
      "\n",
      "<div id=\"text_id2\"> data\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# soup_div = soup.find('div')\n",
    "# print(soup_div.prettify())  # display pretty\n",
    "print('<div> tag first data')\n",
    "print(soup.find(\"div\"))\n",
    "print()\n",
    "\n",
    "# a particular part by using an attribute id\n",
    "# print(soup.find('div', attrs={'id': 'text_id2'}))\n",
    "print('<div id=\"text_id2\"> data')\n",
    "print(soup.find(\"div\", {\"id\": \"text_id2\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract <div id=\"class1\"> text\n",
      "\n",
      "class1's first paragraph\n",
      "naver\n",
      "class1's second paragraph\n",
      "Page1\n",
      "class1's third paragraph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "div_class1 = soup.find('div', {'id': 'class1'})\n",
    "print('extract <div id=\"class1\"> text')\n",
    "print(div_class1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "href link\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "\n",
      "href in href link\n",
      "/pages/page1.html\n",
      "\n",
      "href link text\n",
      "Page1\n",
      "\n",
      "all valuse of href attribute\n",
      "dict_values([['internal_link'], '/pages/page1.html'])\n",
      "\n",
      "href values[0], href values[1]\n",
      "['internal_link'], /pages/page1.html\n",
      "\n",
      "find www.google.com in href\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "google\n"
     ]
    }
   ],
   "source": [
    "# href_link = soup.find('a', {'class': 'internal_link'})\n",
    "href_link = soup.find('a', class_='internal_link')\n",
    "\n",
    "print('href link')\n",
    "print(href_link)\n",
    "print()\n",
    "\n",
    "# print(href_link.get('href'))\n",
    "print('href in href link')\n",
    "print(href_link['href'])  \n",
    "print()\n",
    "\n",
    "print('href link text')\n",
    "print(href_link.text)\n",
    "print()\n",
    "\n",
    "print('all valuse of href attribute')\n",
    "href_values = href_link.attrs.values()\n",
    "print(href_values)\n",
    "print()\n",
    "\n",
    "print('href values[0], href values[1]')\n",
    "print(*href_values, sep=', ')  # instead for clause\n",
    "print()\n",
    "\n",
    "print('find www.google.com in href')\n",
    "# print(soup.find(attrs={'href': 'www.google.com'}))\n",
    "print(soup.find('a', {'href': 'www.google.com'}))\n",
    "print(soup.find('a', {'href': 'www.google.com'}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span> tag values\n",
      "<span class=\"red\">BeautifulSoup Library Examples!</span>\n",
      "\n",
      "<span> tag attribute\n",
      "{'class': ['red']}\n",
      "\n",
      "<span> tag \"class\" attribute\n",
      "['red']\n",
      "\n",
      "only text in <span> tag\n",
      "BeautifulSoup Library Examples!\n"
     ]
    }
   ],
   "source": [
    "print('<span> tag values')\n",
    "print(soup.find('span'))\n",
    "print()\n",
    "\n",
    "print('<span> tag attribute')\n",
    "print(soup.find('span').attrs)\n",
    "print()\n",
    "\n",
    "print('<span> tag \"class\" attribute')\n",
    "print(soup.find('span').attrs['class'])\n",
    "print()\n",
    "\n",
    "print('only text in <span> tag')\n",
    "print(soup.find('span').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find all green or red class attribute values\n",
      "[<span class=\"red\">BeautifulSoup Library Examples!</span>]\n",
      "\n",
      "find_all() return result as a list type\n",
      "['BeautifulSoup Library Examples!']\n",
      "[]\n",
      "\n",
      "[<div id=\"link\">\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>\n",
      "</div>, <div id=\"class1\">\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "<p id=\"third\">class1's third paragraph</p>\n",
      "</div>, <div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>]\n",
      "\n",
      "<div id=\"text_id2\">\n",
      "        Example page\n",
      "        <p>g</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print('find all green or red class attribute values')\n",
    "print(soup.find_all('span', {'class': ('green', 'red')}))\n",
    "print()\n",
    "\n",
    "print('find_all() return result as a list type')\n",
    "print(soup.find_all(text='BeautifulSoup Library Examples!'))\n",
    "print(soup.find_all(text='Library'))\n",
    "print()\n",
    "\n",
    "print(soup.find_all('div'))\n",
    "print()\n",
    "div_tag_values = soup.find_all('div')\n",
    "print(div_tag_values[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "url: www.google.com\n",
      "text: google\n",
      "\n",
      "<a class=\"external_link\" href=\"www.naver.com\">naver</a>\n",
      "url: www.naver.com\n",
      "text: naver\n",
      "\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "url: /pages/page1.html\n",
      "text: Page1\n",
      "\n",
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "\n",
      "\"id\" is \"first\" or \"third\" <p> tag values\n",
      "<p id=\"first\">class1's first paragraph</p>\n",
      "<p id=\"third\">class1's third paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "\n",
    "for alink in links:\n",
    "\tprint(alink)\n",
    "\tprint(f\"url: {alink['href']}\\ntext: {alink.get_text()}\")\n",
    "\tprint()\n",
    "\n",
    "# or excute by a line instead for clause\n",
    "print(soup.find_all('a', {'class': ('external_link', 'internal_link')}))\n",
    "print()\n",
    "\n",
    "print('\"id\" is \"first\" or \"third\" <p> tag values')\n",
    "p_tag = soup.find_all('p', {'id': ['first', 'third']})\n",
    "print(*p_tag, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### select_one(), select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_one(\"head\")\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>BeautifulSoup 활용</title>\n",
      "</head>\n",
      "\n",
      "select_one(\"h1\")\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "\n",
      "select_one(\"footer\")\n",
      "<h1 id=\"footer\">Footer</h1>\n",
      "\n",
      "soup.select_one(\"a.internal_link\")\n",
      "<a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>\n",
      "\n",
      "internal_link text\n",
      "Page1\n",
      "\n",
      "two ways of outer tag to inner tag\n",
      "<a class=\"external_link\" href=\"www.google.com\">google</a>\n",
      "<p id=\"second\">class1's second paragraph</p>\n"
     ]
    }
   ],
   "source": [
    "print('select_one(\"head\")')\n",
    "print(soup.select_one('head'))\n",
    "print()\n",
    "\n",
    "print('select_one(\"h1\")')\n",
    "print(soup.select_one('h1'))\n",
    "print()\n",
    "\n",
    "print('select_one(\"footer\")')\n",
    "# print(soup.select_one('h1#footer'))\n",
    "print(soup.select_one('#footer'))\n",
    "print()\n",
    "\n",
    "print('soup.select_one(\"a.internal_link\")')\n",
    "print(soup.select_one('a.internal_link'))\n",
    "internal_link_clss = soup.select_one('a.internal_link')\n",
    "print()\n",
    "\n",
    "print('internal_link text')\n",
    "print(internal_link_clss.text)\n",
    "print()\n",
    "\n",
    "print('outer tag > innter tag')\n",
    "print(soup.select_one('div#link > a.external_link'))\n",
    "print(soup.select_one('div#class1 p#second'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select() same as find_all()\n",
      "soup.select(\"h1\")\n",
      "<h1 id=\"heading\">Heading 1</h1>\n",
      "<h1 id=\"footer\">Footer</h1>\n",
      "\n",
      "all href values in <a> tag\n",
      "google : www.google.com\n",
      " naver : www.naver.com\n",
      " Page1 : /pages/page1.html\n"
     ]
    }
   ],
   "source": [
    "print('select() same as find_all()')\n",
    "print('soup.select(\"h1\")')\n",
    "print(*soup.select('h1'), sep='\\n')\n",
    "print()\n",
    "\n",
    "print('all href values in <a> tag')\n",
    "url_links = soup.select('a')\n",
    "for link in url_links:\n",
    "\tprint(f'{link.text:>6} : {link[\"href\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a> tag values in <div id=class1>\n",
      "[<a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n",
      "\n",
      "<h1 id = \"heading\" and \"footer\">\n",
      "[<h1 id=\"heading\">Heading 1</h1>, <h1 id=\"footer\">Footer</h1>]\n",
      "\n",
      "<a> tag \"external_link\" and \"internal_link\"\n",
      "[<a class=\"external_link\" href=\"www.google.com\">google</a>, <a class=\"external_link\" href=\"www.naver.com\">naver</a>, <a class=\"internal_link\" href=\"/pages/page1.html\">Page1</a>]\n"
     ]
    }
   ],
   "source": [
    "print('<a> tag values in <div id=class1>')\n",
    "print(soup.select('div#class1 > a'))\n",
    "print()\n",
    "\n",
    "print('<h1 id = \"heading\" and \"footer\">')\n",
    "print(soup.select('#heading, #footer'))\n",
    "print()\n",
    "\n",
    "print('<a> tag \"external_link\" and \"internal_link\"')\n",
    "print(soup.select('a.external_link, a.internal_link'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_anthem = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>애국가</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p id=\"title\">애국가</p>\n",
    "        <p class=\"content\">\n",
    "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>\n",
    "        <p class=\"content\">\n",
    "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.<br>\n",
    "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.<br>\n",
    "        </p>                \n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "anthem = BeautifulSoup(national_anthem, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title and content in national anthem\n",
      "애국가\n",
      "\n",
      "            동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            남산 위에 저 소나무 철갑을 두른 듯 바람서리 불변함은 우리 기상일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            가을 하늘 공활한데 높고 구름 없이 밝은 달은 우리 가슴 일편단심일세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n",
      "\n",
      "            이 기상과 이 맘으로 충성을 다하여 괴로우나 즐거우나 나라 사랑하세.\n",
      "            무궁화 삼천리 화려 강산 대한 사람 대한으로 길이 보전하세.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('title and content in national anthem')\n",
    "print(anthem.select_one('p#title').text)\n",
    "contents = anthem.select('p.content')\n",
    "for content in contents:\n",
    "\tprint(content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### select_one(), select() summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''\n",
    "<div class=\"question\">\n",
    "\t<div id=\"stats1\">\n",
    "\t    <span class=\"item_number\">0</span>\n",
    "\t    <span class=\"item_unit\">votes</span>\n",
    "\t</div>\n",
    "\t<div id=\"stats2\">\n",
    "\t    <span class=\"item_number\">10</span>\n",
    "\t    <span class=\"item_unit\">answer</span>\n",
    "\t</div>\n",
    "\t<div id=\"stats3\">\n",
    "\t\t<span class=\"item_number\">15</span>\n",
    "\t\t<span class=\"item_unit\">views</span>    \n",
    "\t</div>\n",
    "</div>\n",
    "'''\n",
    "q = BeautifulSoup(question, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find values by class name\n",
      "[<span class=\"item_unit\">votes</span>, <span class=\"item_unit\">answer</span>, <span class=\"item_unit\">views</span>]\n",
      "\n",
      "find valuse by id\n",
      "[<div id=\"stats1\">\n",
      "<span class=\"item_number\">0</span>\n",
      "<span class=\"item_unit\">votes</span>\n",
      "</div>]\n",
      "\n",
      "first value in <span class=\"item_number\">\n",
      "<span class=\"item_number\">0</span>\n",
      "\n",
      "all values in <span class=\"item_number\">\n",
      "[<span class=\"item_number\">0</span>, <span class=\"item_number\">10</span>, <span class=\"item_number\">15</span>]\n",
      "\n",
      "<span class=\"item_unit\"> in <div id=\"stats3\">\n",
      "views\n"
     ]
    }
   ],
   "source": [
    "print('find values by class name')\n",
    "print(q.select('.item_unit'))\n",
    "print()\n",
    "\n",
    "print('find valuse by id')\n",
    "print(q.select('#stats1'))\n",
    "print()\n",
    "\n",
    "print('first value in <span class=\"item_number\">')\n",
    "print(q.select_one('span.item_number'))\n",
    "print()\n",
    "\n",
    "print('all values in <span class=\"item_number\">')\n",
    "print(q.select('span.item_number'))\n",
    "print()\n",
    "\n",
    "print('<span class=\"item_unit\"> in <div id=\"stats3\">')\n",
    "print(q.select_one('div#stats3 > span.item_unit').text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6588f8885393062c84ca3cf98915dd362f3bc7e17a1550b6766decbdfd1308b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
